{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walmart Sales Prediction - Model Training and Evaluation\n",
    "\n",
    "This notebook trains multiple machine learning models and compares their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.data_preprocessing import WalmartDataPreprocessor\n",
    "from src.model_training import WalmartModelTrainer\n",
    "from src.visualization import WalmartVisualizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = WalmartDataPreprocessor()\n",
    "\n",
    "# Load data\n",
    "df = preprocessor.load_data('../data/raw/Walmart.csv')\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df = preprocessor.handle_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "df = preprocessor.feature_engineering(df)\n",
    "print(f\"\\nDataset shape after feature engineering: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features (adjust column names based on your dataset)\n",
    "categorical_columns = ['Store', 'Holiday_Flag']  # Update based on actual columns\n",
    "existing_categorical = [col for col in categorical_columns if col in df.columns]\n",
    "\n",
    "if existing_categorical:\n",
    "    df = preprocessor.encode_categorical_features(df, existing_categorical)\n",
    "    print(f\"Encoded columns: {existing_categorical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train-test split\n",
    "TARGET_COLUMN = 'Weekly_Sales'  # Update based on actual target column\n",
    "X_train, X_test, y_train, y_test = preprocessor.prepare_data(df, TARGET_COLUMN)\n",
    "\n",
    "print(f\"\\nFeature columns: {X_train.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = WalmartModelTrainer()\n",
    "trainer.initialize_models()\n",
    "\n",
    "print(f\"Models to train: {list(trainer.models.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models\n",
    "trainer.train_all_models(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results as DataFrame\n",
    "results_df = trainer.get_results_dataframe()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "visualizer = WalmartVisualizer(save_dir='../figures')\n",
    "visualizer.plot_model_comparison(results_df, save_name='model_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_model = trainer.best_model\n",
    "best_model_name = trainer.best_model_name\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"\\nTest Metrics:\")\n",
    "for metric, value in trainer.results[best_model_name]['test_metrics'].items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Plot predictions vs actual\n",
    "visualizer.plot_predictions_vs_actual(\n",
    "    y_test, y_pred,\n",
    "    title=f'{best_model_name} - Predictions vs Actual',\n",
    "    save_name='predictions_vs_actual.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "visualizer.plot_residuals(y_test, y_pred, save_name='residuals.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (if applicable)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_names = X_train.columns.tolist()\n",
    "    visualizer.plot_feature_importance(\n",
    "        best_model, feature_names,\n",
    "        top_n=15,\n",
    "        save_name='feature_importance.png'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "trainer.save_best_model('../models/best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df.to_csv('../results/model_comparison.csv', index=False)\n",
    "print(\"Results saved to ../results/model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Making Predictions on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Make predictions on the first 5 test samples\n",
    "sample_predictions = best_model.predict(X_test.iloc[:5])\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual': y_test.iloc[:5].values,\n",
    "    'Predicted': sample_predictions,\n",
    "    'Difference': y_test.iloc[:5].values - sample_predictions\n",
    "})\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Data preprocessing and feature engineering\n",
    "2. Training multiple machine learning models\n",
    "3. Comparing model performance\n",
    "4. Analyzing the best model\n",
    "5. Making predictions\n",
    "\n",
    "The best model can now be used for production predictions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
